\documentclass[twoside]{projektMagisterski}
\usepackage{polski}
\usepackage[cp1250]{inputenc}
\usepackage{amsmath}
\usepackage{xcolor}

\definecolor{red}{rgb}{0.95,0,0}

%\drukJednostronny

%% tytu³ promotor iautor (\title to komenda standardowa)
\title{Analiza porównawcza algorytmów metaheurystycznych do rozwi¹zywania wybranego problemu optymalizacyjnego}
\promotor{dr in¿. Henryk Josiñski}


%% ka¿dy autor musi mieæ 3 argumenty: imiê nazwisko, nr albumu, opis wk³adu
\autor{Sebastian Nalepka}{111111}
	


%\NumeryNaPoczatku
%% numeracja wzorów tu w³¹czona typu (1.2.3), ta druga to typu (1.2), domyœlnie typu (1)
%\subsectionWzory
% \sectionWzory  

%\rozdzialy


%\literowaNumeracjaDodatkow %% w³¹czy numeracjê dodatków literami
%\rzymskaNumeracjaDodatkow  %%w³¹czy numeracjê dodatków liczbami rzymskimi

%% wy³¹czenie wyjaœnieñ:
\bezWyjasnien

%% standardowe komendy \newtheorem  dzia³aj¹ jak woryginale
\newtheorem{tw}{Twierdzenie}%[subsection]
\newtheorem{twa}{Twierdzenie}%[section]
\newtheorem{dd}{Definicja}%[subsection]

\begin{document}

W otaczaj¹cym nas œwiecie obecnych jest wiele problemów, z którymi zmagaj¹ siê ludzie. Czêœæ z nich jest problemami prostymi, do rozwi¹zania których wystarczy wy³¹cznie niedu¿y nak³ad czasu. Istniej¹ jednak problemy trudniejsze, które wymagaj¹ d³ugotrwa³ych przemyœleñ i obliczeñ po których nie zawsze otrzymujemy najlepsze rozwi¹zanie. Do prostych problemów mo¿emy zaliczyæ codzienne decyzje podejmowane przez ka¿dego cz³owieka dotycz¹ce. Dla przyk³adu jeœli chcemy dojechaæ z punktu A do punktu B komunikacj¹ miejsk¹, wystarczy, ¿e sprawdzimy rozk³ad jazdy i wybierzemy po³¹czenie, które bêdzie pasowa³o nam w kontekœcie godziny przyjazdu na dane miejsce. Przedstawiony problem posiada z go³a inn¹ skalê trudnoœci ze strony przewoŸnika. Wyznaczenie optymalnych tras przewozowych dla okreœlonej liczby œrodków transportu, w celu obs³u¿enia danego zbioru klientów, którzy rozlokowani s¹ w ró¿nych punktach jest kwesti¹ bardzo skomplikowan¹. Znalezienie optymalnych tras, które umo¿liwi¹ przetransportowanie jak najwiêkszej iloœci osób w celu zmaksymalizowania zysku, przy zachowaniu mo¿liwie najkrótszych tras, których zamys³em jest minimalizowanie kosztów poniesionych z transportem jest z³o¿onym problemem, znanym jako jedna z odmian problemu marszrutyzacji, który jest z kolei rozwiniêciem bardzo popularnego problemu komiwoja¿era polegaj¹cego na znalezieniu najkrótszej drogi ³¹cz¹cej wszystkie zdefiniowane uprzednio punkty, zaczynaj¹c i koñcz¹c w tym samym miejscu. Problemy, do rozwi¹zania których potrzebne s¹ ogromne nak³ady obliczeniowe definiowane s¹ jako  problemy optymalizacyjne. W problemach takich liczba mo¿liwych rozwi¹zañ w przestrzeni poszukiwañ z regu³y jest tak du¿a, ¿e niemo¿liwe jest przeszukiwanie wyczerpuj¹ce w celu znalezienia najlepszego z nich. 

\subsection*{Cel pracy}

Celem pracy jest dokonanie analizy porównawczej algorytmu symulowanego wy¿arzania, algorytmu genetycznego oraz roju cz¹stek, która przeprowadzona bêdzie dziêki zaimplementowanej dedykowanej aplikacji bazodanowej, której przeznaczeniem jest zautomatyzowanie procesu szukania minimum globalnego zadanych dla funkcji testowych.

\subsection*{Zawartoœæ pracy}

Dla osi¹gniêcia wy¿ej wymienionego celu zrealizowana zosta³a praca sk³adaj¹ca siê z siedmiu rozdzia³ów oraz wniosków przeprowadzonych doœwiadczeñ wraz z podsumowaniem. W rozdziale pierwszym przedstawiony zosta³ wybór problemu optymalizacyjnego wraz z jego opisem oraz list¹ funkcji testowych, które u¿yte zosta³y do przeprowadzenia badañ. Rozdzia³ drugi przedstawia mo¿liwe sposoby rozwi¹zania wybranego problemu optymalizacyjnego wraz z opisem u¿ytych algorytmów metaheurystycznych. Na bazie dwóch pierwszych rozdzia³ów utworzony zosta³ w rozdziale trzecim projekt automatyzacji przeprowadzanych doœwiadczeñ, na podstawie którego bazowa³a budowana aplikacja. Kolejny rozdzia³ to zastosowane rozwi¹zania technologiczne oraz opis wykorzystanych technologii, bibliotek zewnêtrznych, a tak¿e narzêdzi. Na ich podstawie utworzona zosta³a architektura aplikacji bazodanowej, której specyfikacja umiejscowiona zosta³a w rozdziale pi¹tym. Kolejny rozdzia³ prezentuje ju¿ œciœle aspekt badawczy, który zawiera  opis metod porównawczych zastosowanych algorytmów oraz wyniki doœwiadczeñ dla u¿ytych funkcji testowych, których analiza przeprowadzona zosta³a w rozdziale siódmym zawieraj¹cym wnioski.

\section{Wybór badanego problemu optymalizacji}

\subsection{Opis minimalizacji funkcji ci¹g³ych wielu zmiennych}

W prezentowanej pracy dokonano porównania algorytmów metaheurystycznych odnosz¹c siê do problemu minimalizacji funkcji wielu zmiennych. Problem ten polega na znalezieniu minimum globalnego rzeczywistej funkcji poprzez systematyczne wybieranie parametrów wejœciowych z dozwolonego zakresu i obliczaniu ich wartoœci. Trudnoœæ problemu sprowadza siê do wielkoœci przestrzeni przeszukiwania. Traktuj¹c problem jako czysto matematyczny, funkcja n zmiennych posiada nieskoñczenie wiele wartoœci w ka¿dym wymiarze. Mamy wiêc nieskoñczenie wielk¹ przestrzeñ poszukiwañ. Bior¹c jednak pod wzgl¹d aspekt technologiczny i to, i¿ komputery bazuj¹ na danych skoñczonych, mo¿na w prosty sposób przedstawiæ skalê trudnoœci. W czasie implementacji algorytmu, którego celem jest znalezienie minimum globalnego funkcji, nale¿y wzi¹æ pod uwagê dostêpn¹ dok³adnoœæ obliczeniow¹ maszyny. Zak³adaj¹c, i¿ dok³adnoœæ ta wynosi osiem miejsc po przecinku, ka¿da zmienna, ograniczona w przedziale $[0,100]$ mo¿e przyj¹æ $100*10^8$  ró¿nych wartoœci. Ju¿ dla funkcji dwóch zmiennych, wielkoœæ przestrzeni przeszukiwania wynosi $(100*10^8)^2 = 10^{20} $.

\subsection{Funkcje testowe}

Problem minimalizacji funkcji ci¹g³ych bardzo dobrze nadaje siê do porównania algorytmów metaheurystycznych przez wzgl¹d na powszechnie dostêpne funkcje testowe. Funkcje te, posiadaj¹ pewny specyficzny element, dziêki któremu mo¿liwe jest porównanie wyników otrzymanych przez dany algorytm. Element ten to znajomoœæ minimum globalnego dla danej funkcji testowej. Dziêki znajomoœci wartoœci najlepszej (najmniejszej) dla danej funkcji, wiadomo jak szybko oraz czy w ogóle badany algorytm znalaz³ rozwi¹zanie. Posiadaj¹c t¹ informacjê mo¿na zestawiæ otrzymane rezultaty wszystkich algorytmów pod k¹tem czasowym lub liczby wyliczeñ wartoœci funkcji dla ustalonych przez algorytm punktów.
Do analizy wybranych zosta³o piêæ funkcji testowych, których dobór bra³ pod uwagê stopieñ ich skomplikowania. Ka¿da z funkcji posiada specyficzne w³aœciwoœci, które zostan¹ wziête pod uwagê podczas porównania rezultatów algorytmów heurystycznych.

\subsubsection{Funkcja Bochachevsky’ego N. 1}
\subsubsection{Funkcja Rosenbrocka}
\subsubsection{Funkcja Easoma}
\subsubsection{Funkcja Eggholdera}
\subsubsection{Funkcje Griewanka}
\subsubsection{Funkcje testowe}

\textcolor{brown}{Opis funkcji wraz z ich w³aœciwoœciami opisaæ po definitywnym ich wyborze (poczekaæ na fazê testów)}

\section{Metody rozwi¹zania wybranego problemu optymalizacji}

\subsection{Algorytmy dok³adne}

Klasycznym podejœciem do znalezienia minimalnej wartoœci zadanej funkcji testowej jest próba porównania wartoœci funkcji dla ka¿dych mo¿liwych parametrów wejœciowych i wybrania w ten sposób optymalnego rozwi¹zania. W rzeczywistoœci jednak takie rozwi¹zanie nie jest praktyczne przez wzgl¹d na olbrzymi¹ mo¿liw¹ liczbê takich parametrów. Jak ju¿ wspomniano w rozdziale 1.1  liczba rozwi¹zañ dla funkcji ograniczonej ju¿ do dwóch zmiennych mo¿e wynieœæ $10^{20}$, a w przypadku trzech zmiennych – $10^{30}$. Zak³adaj¹c, i¿ mo¿liwe by by³o wyliczenie miliarda wartoœci funkcji na sekundê, to w godzinê wartoœæ ta wynosi³aby  $3.6*10^{12}$, a w rok – $3.2*10^{16}$. Prowadz¹c dalej obliczenia wychodzi, i¿ wyliczenie $10^{20}$ wartoœci funkcji trwa³oby oko³o 3125 lat. Widaæ, i¿ liczba kombinacji jest tak du¿a, i¿ takie podejœcie jest niemo¿liwe do wykonania w akceptowalnym czasie.

\subsection{Metaheurystyki optymalizacyjne}

Analizuj¹c podejœcie z rozdzia³u 2.1, mo¿e przyjœæ na myœl sposób, który polegaæ bêdzie na wyliczaniu wartoœci funkcji dla wyrywkowych parametrów. Sk¹d jednak wiadomo które punkty wybraæ? Na podstawie czego bazowaæ? W przypadku problemów, w których przez wzgl¹d na czas niemo¿liwe jest dojœcie do rozwi¹zania na ratunek przychodz¹ algorytmy heurystyczne, które umo¿liwiaj¹ skrócenie czasu obliczeñ. Cen¹ któr¹ trzeba jednak za to zap³aciæ jest otrzymanie potencjalnie gorszego rozwi¹zania od rozwi¹zania najlepszego. Samo pojêcie heurystyki pochodzi od greckiego s³owa heuresis, które znaczy ‘odnaleŸæ’. Metody heurystyczne polegaj¹ na u¿yciu regu³ oraz faktów, które uzyskane na drodze badania danego problemu, umo¿liwiaj¹ jego rozwi¹zanie lub zbli¿enie siê do poprawnej odpowiedzi. Podejœcie heurystyczne stosowane mo¿e byæ w sposób piêtrowy, tworz¹c metaheurystyki. Metaheurystyka jest to ogólny algorytm do rozwi¹zywania problemów obliczeniowych, który inspiracjê czêsto bierze z mechanizmów biologicznych lub fizycznych. Okreœlenie to oznacza tak zwan¹ heurystykê wy¿szego poziomu, co wynika z faktu, i¿ algorytmy tego typu bezpoœrednio nie rozwi¹zuj¹ ¿adnego problemu, a wy³¹cznie podaj¹ metodê na utworzenie odpowiedniego algorytmu. 


\subsubsection{Metoda optymalizacji rojem cz¹stek}

Metoda roju cz¹stek (PSO – Particle Swarm Optimization) jest przyk³adem optymalizacji z kategorii metod inteligencji stadnej. Powsta³a ona w wyniku inspiracji biologicznej, której Ÿród³em by³ uk³ad lotu stada ptaków tworzony w celu znalezienia po¿ywienia lub gniazda oraz unikniêcia drapie¿ników. Zastosowanie prostych zasad umo¿liwia ptakom zsynchronizowany oraz bezkolizyjnych ruch, który daje efekt zachowania jednego organizmu. Ruch stada ptaków, czy ³awicy ryb jest wypadkow¹ dzia³ania wszystkich osobników i koncentruje siê na utrzymaniu optymalnego dystansu od swoich s¹siadów, przy jednoczesnym pod¹¿aniem za liderem. Badania nad optymalizacj¹ roju cz¹stek zapocz¹tkowano od próby graficznego zasymulowania zachowañ takich grup. Bardzo szybko okaza³o siê, i¿ stworzony matematyczny model mo¿e byæ równie¿ zastosowany jako metoda optymalizacyjna.
W optymalizacji rojem cz¹stek rozwi¹zania (cz¹stki) wspó³pracuj¹ ze sob¹ w celu odnalezienia cz¹stki optymalnej. W czasie procesu optymalizacji nastêpuje zmiana po³o¿enia ka¿dej cz¹stki w przestrzeni rozwi¹zañ poprzez wyznaczenie wektora prêdkoœci. Wektor ten jest modyfikowany przy u¿yciu informacjê o historii poszukiwañ danej cz¹stki oraz jej cz¹stek s¹siednich. Metoda PSO w problemie optymalizacji funkcji wielowymiarowych d¹¿y do otrzymania cz¹steczki, która reprezentuje jak najmniejsz¹ wartoœæ funkcji i mo¿e byæ opisana dwoma równaniami:

\begin{equation}
v=W*v+c_1*r_1*(p-x)+c_2*r_2*(g-x)
\end{equation}
gdzie,

$v$ - aktualny wektor prêdkoœci cz¹stki

$W$ – parametr z zakresu $[0,1]$, który determinuje wp³yw poprzedniego po³o¿enia cz¹stki na jej obecn¹ pozycjê

$p$ - najlepsze rozwi¹zanie dla cz¹stki

$g$ – najlepsze rozwi¹zanie dla s¹siedztwa cz¹stek

$r_1,r_2$ – losowe liczby z zakresu $[0,1]$

$c_1,c_2$ – parametry skaluj¹ce z zakresu $[0,1]$

Nawi¹zuj¹c do powy¿szych równañ, ka¿da cz¹stka roju przeszukuje przestrzeñ rozwi¹zañ, zmieniaj¹c po³o¿enie na podstawie swoich najlepszych rozwi¹zañ $p_i$, jednoczeœnie wykorzystuj¹c informacjê o najlepszym rozwi¹zaniu w s¹siedztwie $p_t$. Parametry skaluj¹ce umo¿liwiaj¹ kontrolê wp³ywu danych czêœci wektora prêdkoœci na wynik. W przypadku, w którym $c_1$ bêdzie równe zero, cz¹stka bêdzie wykorzystywa³a tylko i wy³¹cznie informacjê o najlepszym rozwi¹zaniu w roju. Z kolei jeœli wartoœæ parametru $c_2$ zostanie ustawiona na zero, cz¹stka bêdzie poszukiwa³a rozwi¹zania samodzielnie, bez uwzglêdnienia rozwi¹zañ, które uzyskane zosta³y przez inne cz¹stki. 

\subsubsection{Symulowane wy¿arzanie}

Algorytm symulowanego wy¿arzania po raz pierwszy zosta³ opisany w 1953 roku przez Nicolasa Metropolisa. Sposób dzia³ania algorytmu jak i równie¿ jego nazwa odnosi siê do procesów fizycznych, które wykorzystywane s¹ w metalurgii. Proces wy¿arzania polega na rozgrzaniu cia³a sta³ego do okreœlonej temperatury, a nastêpnie jego powolnym studzeniu. Konsekwencj¹ tego dzia³ania jest zmiana struktury krystalicznej materia³u, który poddany zosta³ wy¿arzaniu. W czasie procesu och³adzania metali dostrze¿ono, i¿ cz¹steczki cia³a
wraz z jego powolnym sch³adzaniem tworz¹ bardziej regularne struktury, ni¿ w przypadku szybszego obni¿enia temperatury, kiedy to ch³odzone cz¹steczki nie potrafi¹ znaleŸæ optymalnego po³o¿enia.
Algorytm symulowanego wy¿arzania jest usprawnieniem starszych metod iteracyjnych, które polega³y na ci¹g³ym ulepszaniu istniej¹cego rozwi¹zania do momentu braku mo¿liwoœci jego poprawy. W metodach tych zatrzymanie algorytmu mog³o nast¹piæ przy rozwi¹zaniu pseudo-optymalnym – lokalnym minimum. Nie istnia³a wówczas mo¿liwoœæ wyjœcia z owego lokalnego minima i kierowania siê w kierunku minimum globalnego. Bardzo wa¿n¹ cech¹ opisywanego algorytmu jest mo¿liwoœæ wyboru, z pewnym prawdopodobieñstwem, gorszego rozwi¹zania. Dziêki temu problem utkniêcia w lokalnym minimum nie jest ju¿ groŸny. Za wybór gorszego rozwi¹zania ma wp³yw podstawowy parametr przeniesiony z podstaw termodynamicznych algorytmu – temperatura. Im jest ona wy¿sza, tym wiêksze istnieje prawdopodobieñstwo wyboru i zaakceptowania gorszego rozwi¹zania. W czasie dzia³ania algorytmu, temperatura obni¿a siê i dzia³anie algorytu zbli¿a siê w ten sposób do typowych metod iteracyjnych.
W celu wykonania algorytmu symulowanego wy¿arzania w kontekœcie optymalizacji funkcji wielu zmiennych nale¿y na pocz¹tku losowo wygenerowaæ punkt startowy, który mieœci siê na p³aszczyŸnie poszukiwañ, wyliczyæ dla niego wartoœæ funkcji oraz wybraæ maksymaln¹ temperaturê startow¹ z dostêpnego zakresu [0,100]. Ka¿da iteracja polega na wyborze losowego rozwi¹zania z s¹siedztwa, wyliczenia dla niego wartoœci funkcji i porównaniu z obecnie najlepszym rezultatem oraz obni¿eniu temperatury. W przypadku, w którym wartoœæ funkcji nowego punktu jest mniejsza (lepsza), jest on zaklasyfikowany jako najlepszy. W przeciwnej sytuacji punkt nie jest natychmiastowo odrzucany. Algorytm akceptuje gorsze rezultaty bazuj¹c na funkcji akceptacyjnej, która prezentuje siê nastêpuj¹co:

\begin{equation}
\frac{1}{1+exp(\frac{\Delta}{max(T)})}
\end{equation}
gdzie,

$\Delta$ – ró¿nica wartoœci starego i nowego punktu

$T$ – wartoœæ temperatury

W sytuacji, w której $\Delta$ i $T$ s¹ wartoœciami dodatnimi, prawdopodobieñstwo akceptacji mieœci siê pomiêdzy 0 i $\frac{1}{2}$. Ni¿sza temperatura prowadzi do mniejszego prawdopodobieñstwa zaakceptowania gorszego rezultatu. Podobnie jest z delt¹ – im wiêksza delta tym mniejsza szansa na zaakceptowanie.

\subsubsection{Algorytm genetyczny}

Model algorytmu genetycznego po raz pierwszy zaprezentowany zosta³ w 1975 roku przez Johna Hollanda, który w pracy „Adaptation in Natural and Artifical Systems” przedstawi³ fundamenty za³o¿eñ dotycz¹cych adaptacji darwinowskiej teorii ewolucji w systemach informatycznych.  
W opisie algorytmu genetycznego pos³uguje siê powszechn¹ terminologi¹ biologiczn¹. Z tego te¿ powodu mówi siê, i¿ algorytmy genetyczne przetwarzaj¹ populacjê osobników, którzy reprezentuj¹ rozwi¹zanie danego problemu. Ka¿dy element populacji nazywany jest chromosomem, a jego sk³adowe genami. Allele z kolei, s¹ to mo¿liwe stany (wartoœci) genu, które umiejscowione s¹ na pozycjach zdefiniowanych jako locus. W badanych modelach komputerowych, osobniki (chromosomy) mog¹ byæ opisane jako ró¿ne struktury – zaczynaj¹c na ³añcuchach binarnych, a koñcz¹c na bardzo z³o¿onych obiektach. W okreœlonej iteracji zwanej zamiennie pokoleniem albo generacj¹, dane chromosomy na bazie okreœlonej miary ich dostrojenia podlegaj¹ ocenie. Ocena ta skutkuje wyborem najlepiej przystosowanych osobników, które wezm¹ udzia³ w kolejnych iteracjach algorytmu. Nim jednak wybrane osobniki populacji utworz¹ now¹ generacjê, zostaj¹ poddane modyfikacjom spowodowanym podstawowymi operacjami genetycznymi – krzy¿owaniem, selekcj¹ oraz mutacj¹.
W kontekœcie problemu optymalizacji funkcji wielu zmiennych, inicjalizacja algorytmu genetycznego polega na wygenerowaniu populacji pocz¹tkowej, która z³o¿ona jest z okreœlonej liczby chromosomów. Ka¿dy chromosom reprezentowany w populacji posiada tak¹ sam¹ d³ugoœæ, która ustalona jest zale¿nie od rozwi¹zywanego problemu na etapie implementowania algorytmu. Przed nast¹pieniem etapu generowania musi byæ jednak okreœlony sposób kodowania informacji zawartej w chromosomie, która dotyczy rozwi¹zania. W algorytmie Hollanda nie by³o domyœlnie zdefiniowanego sposobu kodowania chromosomów. Powszechnie uznaje siê jednak, i¿ w algorytmie genetycznym stosuje siê kodowanie binarne. Takie te¿ kodowanie jest zastosowane w kontekœcie omawianego problemu optymalizowania funkcji wielu zmiennych. Kolejnym etapem, który nastêpuje po wygenerowaniu populacji pocz¹tkowej oraz wyborze kodowania chromosomów jest wyznaczenie jakoœci chromosomów danej populacji. W tym celu obliczana jest wartoœæ tak zwanej funkcji oceny, która definiuje poziom dopasowania konkretnego chromosomu. Tym sposobem mo¿na stwierdziæ, które chromosomy lepiej rozwi¹zuj¹ dane zagadnienie, a które gorzej. Znalezienie rozwi¹zania danego problemu sprowadza siê do znalezienia ekstremum wspomnianej funkcji oceny. Kolejn¹ czêœci¹ algorytmu jest zastosowanie mechanizmu selekcji, który definiuje sposób wyboru rozwi¹zañ rodzicielskich, z których tworzone bêd¹ tak zwane rozwi¹zania potomne u¿yte w nastêpnej generacji. Podstawowy algorytm genetyczny w operacji selekcji stosuje metodê ruletki. Metoda ta polega na przydzieleniu ka¿demu chromosomowi z danej populacji prawdopodobieñstwa wed³ug wzoru:

\begin{equation}
p_i = \frac{f_i}{\sum_{j=1}^{N}f_j}
\end{equation}

gdzie,
$f_i$ - wartoœæ funkcji oceny chromosomu i-tego
$p_i$ – prawdopodobieñstwo reprodukcji

W celu wybrania puli rodzicielskiej, ko³o ruletki o obwodzie jeden dzielone jest na czêœci o d³ugoœci $p_i$, a nastêpnie z zakresu $[0,1]$ losowana jest liczba, która jednoznacznie identyfikuje punkt na ruletce, a co za tym idzie konkretny chromosom. Chromosom ten brany bêdzie pod uwagê w procesie nastêpnej reprodukcji, a losowanie powtarzane jest tak d³ugo, a¿ wylosowana zostanie ustalona liczba chromosomów. W problemie minimalizacji funkcji wielu zmiennych istnieje mo¿liwoœæ, i¿ wartoœæ funkcji oceny bêdzie ujemna. W celu zniwelowania problemu ujemnego prawdopodobieñstwa powy¿szy wzór zosta³ zmodyfikowany stosuj¹c skalowanie przystosowania:

\begin{equation}
p_i = \frac{f_i-f_{min}}{\sum_{j=1}^{N}f_j-f_{min}}
\end{equation} 

gdzie $f_{min}$ jest wartoœci¹ funkcji przystosowania najgorszego chromosomu. \newline
 
Po etapie selekcji pozostaje do zdefiniowania kwestia wymiany pokoleñ. W implementacjach czêsto stosowana jest metoda ca³kowitego zastêpowania, w której ca³a aktualna populacja, podlega operacjom krzy¿owania i mutacji. Innym sposobem jest metoda zastêpowania czêœciowego, w której czêœæ najlepszych chromosomów obecnej populacji przechodzi do populacji potomnej be¿ ¿adnych zmian, a pozosta³e elementy z kolei bior¹ udzia³ w operacji krzy¿owania i mutacji. Czêsto stosowan¹ praktyk¹ jest zastosowanie zastêpowana elitarnego, w którym na podstawie parametru okreœlaj¹cego wielkoœæ elity, czêœæ najlepszych osobników jest kopiowana do nowej generacji ju¿ na samym pocz¹tku. Umo¿liwia to ‘pamiêtanie’ najlepszych chromosomów które mog³y byæ zmienione poprzez dzia³anie operatorów genetycznych.

Pierwszym z takich operatorów jest krzy¿owanie, które jest operacj¹ umo¿liwiaj¹c¹ tworzenie nowych rozwi¹zañ. Jego koncept bazuje na procesie rozmna¿ania organizmów, w czasie trwania których dziecko dziedziczy czêœæ genów rodziców. W kontekœcie omawianego algorytmu genetycznego, krzy¿owanie polega na przeciêciu chromosomów w ustalonym punkcie i ich wzajemnego zamienienia. 
Drugim operatorem genetycznym jest mutacja, która umo¿liwia wprowadzenie nowego elementu do populacji poprzez tworzenie ró¿norodnoœci. Analogicznie jak w otaczaj¹cym nas œwiecie, tak i w algorytmie genetycznym, mutacje zdarzaj¹ siê rzadko. Ich skala zazwyczaj zale¿y od parametru, który przyjmuje niskie wartoœci. W odniesieniu do chromosomów w postaci binarnej, mutacja mo¿e polegaæ na losowej zamianie losowego genu na wartoœæ przeciwn¹. Tak utworzona nowa generacja ponownie przechodzi przez wszystkie punkty algorytmu. Dzieje siê tak a¿ do czasu, w którym spe³nione zostan¹ warunki zatrzymania, które w kontekœcie przedstawianego zagadnienia opisane zosta³y w rozdziale 6.1 opisuj¹cym metody porównawcze wybranych algorytmów obejmuj¹ce w swojej treœci warunki stopu opisanych trzech metaheurystyków.

\section{Automatyzacja przeprowadzanych badañ}
\section{Wykorzystane rozwi¹zania technologiczne}

Obecny rozdzia³ obejmuje opis wykorzystanych technologii, które umo¿liwi³y implementacjê aplikacji. Opis ten dotyczy jêzyka programowania, w którym napisany zosta³ backend aplikacji oraz silnika graficznego aplikacji i jêzyka zapytañ bazy danych

\subsection{Zastosowane narzêdzia}

\subsubsection{Matlab}

\subsubsection{SQL Server Management Studio 17}

W czasie pracy nad aplikacj¹ automatyzuj¹c¹ proces przeprowadzania testów wykorzystano darmowe narzêdzie, którego przeznaczeniem jest zarz¹dzanie baz¹ danych - SQL Server Management Studio 17. Potrzeba u¿ycia narzêdzia wynik³a z istniej¹cej infrastruktury aplikacji, która opiera siê na rozwi¹zaniach Microsoftu. Zastosowane narzêdzie znacznie u³atwi³o pracê i wspomog³o proces projektowania bazy danych dziêki funkcjonalnoœci generowania diagramów, które umo¿liwi³y podgl¹d struktury bazy oraz relacji pomiêdzy poszczególnymi tabelami. Kolejn¹ olbrzymi¹ zalet¹ SQL Management Studio jest mo¿liwoœæ tworzenia zapytañ bazodanowych, które pozwalaj¹ w bardzo elastyczny sposób pogrupowaæ olbrzymie iloœci danych w wybrany przez u¿ytkownika sposób. Umo¿liwia to w szybkim tempie stworzenie statystyk zastosowanych algorytmów, które dynamicznie bêd¹ siê aktualizowa³y wraz z nap³ywem kolejnych danych do bazy.

\subsubsection{Visual Studio 2015}


\subsection{Wykorzystane biblioteki zewnêtrzne}
\subsubsection{Matlab Application Type Library v.1.0}

\subsection{Zastosowane technologie}
\subsubsection{.NET Framework/C\#}
\subsubsection{WPF}
\subsubsection{XAML}
\subsubsection{TSQL}

\section{Architektura budowanej aplikacji}
\subsection{Architektura aplikacji}
\subsubsection{Wzorce architektoniczne oprogramowania}
\subsubsection{Zastosowany wzorzec architektoniczny – MVVM}
\subsubsection{Model aplikacji}
\subsection{Architektura bazy danych}
\subsubsection{MS-SQL – Zastosowany system zarz¹dzania baz¹ danych}
\subsubsection{Budowa bazy danych u¿ytej w projekcie}
\subsection{Komunikacja bazy danych z projektem programistycznym}
\subsubsection{Mapowanie obiektowo-relacyjne}
\subsubsection{Zastosowane narzêdzie ORM – Entity Framework}
\subsection{Komunikacja Matlaba z projektem programistycznym}
\subsection{Opis okna u¿ytkownika}
\section{Badania eksperymentalne}
\subsection{Metody porównawcze wybranych algorytmów}
\subsection{Opis przeprowadzonych badañ}
\subsection{Wyniki doœwiadczeñ dla zadanych funkcji testowych}
\subsubsection{Funkcja Bochachevsky’ego}
\subsubsection{Funkcja Beale’a}
\subsubsection{Funkcja Rosenbrocka}
\subsubsection{Funkcja Easoma }
\subsubsection{Funkcja Eggholdera}
\subsubsection{Funkcja Griewanka}
\section{Wnioski}
\section{Podsumowanie}

\end{document}
